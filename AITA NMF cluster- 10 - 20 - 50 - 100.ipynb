{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('aita_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>edited</th>\n",
       "      <th>verdict</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_asshole</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>1.393279e+09</td>\n",
       "      <td>[AITA] I wrote an explanation in TIL and came ...</td>\n",
       "      <td>[Here is the post in question](http://www.redd...</td>\n",
       "      <td>False</td>\n",
       "      <td>asshole</td>\n",
       "      <td>52</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>1.393281e+09</td>\n",
       "      <td>[AITA] Threw my parent's donuts away</td>\n",
       "      <td>My parents are diabetic, morbidly obese, and a...</td>\n",
       "      <td>1393290576.0</td>\n",
       "      <td>asshole</td>\n",
       "      <td>140</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>1.393285e+09</td>\n",
       "      <td>I told a goth girl she looked like a clown.</td>\n",
       "      <td>I was four.</td>\n",
       "      <td>False</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>74</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1yuc78</td>\n",
       "      <td>1.393287e+09</td>\n",
       "      <td>[AItA]: Argument I had with another redditor i...</td>\n",
       "      <td>http://www.reddit.com/r/HIMYM/comments/1vvfkq/...</td>\n",
       "      <td>1393286962.0</td>\n",
       "      <td>everyone sucks</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yueqb</td>\n",
       "      <td>1.393288e+09</td>\n",
       "      <td>[AITA] I let my story get a little long and bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     timestamp                                              title  \\\n",
       "0  1ytxov  1.393279e+09  [AITA] I wrote an explanation in TIL and came ...   \n",
       "1  1yu29c  1.393281e+09               [AITA] Threw my parent's donuts away   \n",
       "2  1yu8hi  1.393285e+09        I told a goth girl she looked like a clown.   \n",
       "3  1yuc78  1.393287e+09  [AItA]: Argument I had with another redditor i...   \n",
       "4  1yueqb  1.393288e+09  [AITA] I let my story get a little long and bo...   \n",
       "\n",
       "                                                body        edited  \\\n",
       "0  [Here is the post in question](http://www.redd...         False   \n",
       "1  My parents are diabetic, morbidly obese, and a...  1393290576.0   \n",
       "2                                        I was four.         False   \n",
       "3  http://www.reddit.com/r/HIMYM/comments/1vvfkq/...  1393286962.0   \n",
       "4                                                NaN         False   \n",
       "\n",
       "           verdict  score  num_comments  is_asshole  \n",
       "0          asshole     52          13.0           1  \n",
       "1          asshole    140          27.0           1  \n",
       "2  not the asshole     74          15.0           0  \n",
       "3   everyone sucks     22           3.0           1  \n",
       "4  not the asshole      6           4.0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaners(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    #words = sentence.split()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data['lower_split'] = data['body'].astype(str).apply(lambda x : cleaners(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#text = word_tokenize('Rock Cutting Faster Going Corpora')\n",
    "def postag_n_lemat(text):\n",
    "    text = text.lower()\n",
    "    posts = pos_tag(text.split())\n",
    "    new_sent = []\n",
    "    for i in range (0, len(posts)):\n",
    "        #print(posts[i])        \n",
    "        word = posts[i][0]\n",
    "        tag = posts[i][1]\n",
    "        if tag.startswith('R'):\n",
    "            new_sent.append(lemmatizer.lemmatize(word,'r'))\n",
    "        elif tag.startswith('N'):\n",
    "            new_sent.append(lemmatizer.lemmatize(word,'n'))\n",
    "        elif tag.startswith('V'):\n",
    "            new_sent.append(lemmatizer.lemmatize(word,'v'))\n",
    "        elif tag.startswith('J'):\n",
    "            new_sent.append(lemmatizer.lemmatize(word, 'a'))\n",
    "        else:\n",
    "            new_sent.append(lemmatizer.lemmatize(word))\n",
    "    joined = ' '.join(word for word in new_sent)\n",
    "    return joined\n",
    "    #nltk.pos_tag(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'where be the rock go in their pay and park in the parked spot with good corpus'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postag_n_lemat('Where are the rocks going in their paying and parking in the parked spot with better Corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['lemats'] = data['body'].astype(str).apply(lambda x : postag_n_lemat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>edited</th>\n",
       "      <th>verdict</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_asshole</th>\n",
       "      <th>lemats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>1.393279e+09</td>\n",
       "      <td>[AITA] I wrote an explanation in TIL and came ...</td>\n",
       "      <td>[Here is the post in question](http://www.redd...</td>\n",
       "      <td>False</td>\n",
       "      <td>asshole</td>\n",
       "      <td>52</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[here be the post in question](http://www.redd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>1.393281e+09</td>\n",
       "      <td>[AITA] Threw my parent's donuts away</td>\n",
       "      <td>My parents are diabetic, morbidly obese, and a...</td>\n",
       "      <td>1393290576.0</td>\n",
       "      <td>asshole</td>\n",
       "      <td>140</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>my parent be diabetic, morbidly obese, and add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>1.393285e+09</td>\n",
       "      <td>I told a goth girl she looked like a clown.</td>\n",
       "      <td>I was four.</td>\n",
       "      <td>False</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>74</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>i be four.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1yuc78</td>\n",
       "      <td>1.393287e+09</td>\n",
       "      <td>[AItA]: Argument I had with another redditor i...</td>\n",
       "      <td>http://www.reddit.com/r/HIMYM/comments/1vvfkq/...</td>\n",
       "      <td>1393286962.0</td>\n",
       "      <td>everyone sucks</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.reddit.com/r/himym/comments/1vvfkq/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yueqb</td>\n",
       "      <td>1.393288e+09</td>\n",
       "      <td>[AITA] I let my story get a little long and bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     timestamp                                              title  \\\n",
       "0  1ytxov  1.393279e+09  [AITA] I wrote an explanation in TIL and came ...   \n",
       "1  1yu29c  1.393281e+09               [AITA] Threw my parent's donuts away   \n",
       "2  1yu8hi  1.393285e+09        I told a goth girl she looked like a clown.   \n",
       "3  1yuc78  1.393287e+09  [AItA]: Argument I had with another redditor i...   \n",
       "4  1yueqb  1.393288e+09  [AITA] I let my story get a little long and bo...   \n",
       "\n",
       "                                                body        edited  \\\n",
       "0  [Here is the post in question](http://www.redd...         False   \n",
       "1  My parents are diabetic, morbidly obese, and a...  1393290576.0   \n",
       "2                                        I was four.         False   \n",
       "3  http://www.reddit.com/r/HIMYM/comments/1vvfkq/...  1393286962.0   \n",
       "4                                                NaN         False   \n",
       "\n",
       "           verdict  score  num_comments  is_asshole  \\\n",
       "0          asshole     52          13.0           1   \n",
       "1          asshole    140          27.0           1   \n",
       "2  not the asshole     74          15.0           0   \n",
       "3   everyone sucks     22           3.0           1   \n",
       "4  not the asshole      6           4.0           0   \n",
       "\n",
       "                                              lemats  \n",
       "0  [here be the post in question](http://www.redd...  \n",
       "1  my parent be diabetic, morbidly obese, and add...  \n",
       "2                                         i be four.  \n",
       "3  http://www.reddit.com/r/himym/comments/1vvfkq/...  \n",
       "4                                                nan  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(['way', 'didn','things', 'say', 'think', 'said', 've', 'want', 'know', 'feel', 'really', 'don', 'just', 'like'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'didn',\n",
       "           'do',\n",
       "           'don',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'feel',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'just',\n",
       "           'keep',\n",
       "           'know',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'like',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'really',\n",
       "           'said',\n",
       "           'same',\n",
       "           'say',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'things',\n",
       "           'think',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           've',\n",
       "           'very',\n",
       "           'via',\n",
       "           'want',\n",
       "           'was',\n",
       "           'way',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<97628x13972 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7889824 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mystop = TfidfVectorizer(max_df = .7, min_df = 20, stop_words = my_stop_words)\n",
    "dtm_mystop = tfidf_mystop.fit_transform(data['lemats'].values.astype('U'))\n",
    "dtm_mystop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 15 words for topic#0\n",
      "['stop', 'look', 'x200b', 'girl', 'time', 'relationship', 'people', 'guy', 'start', 'ask', 'thing', 'make', 'try', 'talk', 'tell']\n",
      "\n",
      "\n",
      "The top 15 words for topic#1\n",
      "['old', 'aunt', 'grandma', 'live', 'house', 'year', 'father', 'tell', 'mother', 'family', 'parent', 'brother', 'sister', 'dad', 'mom']\n",
      "\n",
      "\n",
      "The top 15 words for topic#2\n",
      "['yard', 'care', 'house', 'vet', 'leash', 'neighbor', 'owner', 'cat', 'animal', 'bark', 'pet', 'walk', 'puppy', 'dogs', 'dog']\n",
      "\n",
      "\n",
      "The top 15 words for topic#3\n",
      "['afford', 'account', 'cost', 'use', 'gift', 'live', 'help', 'ask', 'save', 'job', 'month', 'rent', 'buy', 'money', 'pay']\n",
      "\n",
      "\n",
      "The top 15 words for topic#4\n",
      "['night', 'meet', 'tell', 'girl', 'birthday', 'plan', 'close', 'boyfriend', 'invite', 'friends', 'best', 'hang', 'party', 'group', 'friend']\n",
      "\n",
      "\n",
      "The top 15 words for topic#5\n",
      "['christmas', 'parent', 'father', 'old', 'wedding', 'baby', 'year', 'mother', 'child', 'son', 'daughter', 'husband', 'kid', 'family', 'wife']\n",
      "\n",
      "\n",
      "The top 15 words for topic#6\n",
      "['wake', 'leave', 'home', 'door', 'clean', 'apartment', 'live', 'stay', 'night', 'bed', 'cat', 'house', 'roommate', 'sleep', 'room']\n",
      "\n",
      "\n",
      "The top 15 words for topic#7\n",
      "['pull', 'pick', 'minute', 'gas', 'street', 'road', 'home', 'ride', 'walk', 'driver', 'spot', 'parking', 'park', 'drive', 'car']\n",
      "\n",
      "\n",
      "The top 15 words for topic#8\n",
      "['need', 'come', 'schedule', 'help', 'company', 'bos', 'shift', 'manager', 'home', 'hour', 'week', 'time', 'day', 'job', 'work']\n",
      "\n",
      "\n",
      "The top 15 words for topic#9\n",
      "['drink', 'ask', 'table', 'lunch', 'buy', 'birthday', 'tip', 'restaurant', 'make', 'meal', 'order', 'dinner', 'cook', 'food', 'eat']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nmf_model2 = NMF(n_components = 10)\n",
    "nmf_model2.fit(dtm_mystop)\n",
    "for index, topic in enumerate(nmf_model2.components_):\n",
    "  print(f\"The top 15 words for topic#{index}\")\n",
    "  print([tfidf_mystop.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "  #print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19361\n",
       "5    14638\n",
       "4    10861\n",
       "8    10210\n",
       "6     9507\n",
       "1     9111\n",
       "3     8447\n",
       "9     7235\n",
       "7     5132\n",
       "2     3126\n",
       "Name: MystopTopic_10, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results2 = nmf_model2.transform(dtm_mystop)\n",
    "data['MystopTopic_10'] = topic_results2.argmax(axis = 1)\n",
    "data['MystopTopic_10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 words for topic#0\n",
      "['read', 'texted', 'email', 'block', 'contact', 'reply', 'respond', 'text', 'send', 'message']\n",
      "The top 10 words for topic#1\n",
      "['care', 'mad', 'aunt', 'live', 'yell', 'divorce', 'step', 'stepdad', 'grandma', 'mom']\n",
      "The top 10 words for topic#2\n",
      "['neighbor', 'vet', 'leash', 'pet', 'animal', 'owner', 'bark', 'puppy', 'dogs', 'dog']\n",
      "The top 10 words for topic#3\n",
      "['months', 'sign', 'couple', 'deposit', 'landlord', 'place', 'ago', 'lease', 'month', 'rent']\n",
      "The top 10 words for topic#4\n",
      "['insurance', 'debt', 'payment', 'loan', '50', 'half', 'split', 'offer', 'cost', 'pay']\n",
      "The top 10 words for topic#5\n",
      "['funeral', 'vacation', 'extended', 'sibling', 'holiday', 'visit', 'close', 'thanksgiving', 'member', 'family']\n",
      "The top 10 words for topic#6\n",
      "['dishes', 'laundry', 'cleaning', 'sink', 'mess', 'bathroom', 'kitchen', 'wash', 'dish', 'clean']\n",
      "The top 10 words for topic#7\n",
      "['new', 'cars', 'road', 'vehicle', 'driver', 'damage', 'gas', 'accident', 'insurance', 'car']\n",
      "The top 10 words for topic#8\n",
      "['working', 'need', 'morning', 'hard', 'project', 'week', 'schedule', 'shift', 'hour', 'work']\n",
      "The top 10 words for topic#9\n",
      "['pizza', 'weight', 'order', 'vegan', 'meat', 'lunch', 'meal', 'cook', 'food', 'eat']\n",
      "The top 10 words for topic#10\n",
      "['twin', 'si', 'sisters', 'little', 'law', 'old', 'young', 'nephew', 'niece', 'sister']\n",
      "The top 10 words for topic#11\n",
      "['asshole', 'feeling', 'recently', 'good', 'mutual', 'friendship', 'close', 'friends', 'best', 'friend']\n",
      "The top 10 words for topic#12\n",
      "['niece', 'bro', 'brothers', 'nephew', 'sil', 'law', 'little', 'old', 'young', 'brother']\n",
      "The top 10 words for topic#13\n",
      "['care', 'shelter', 'adopt', 'vet', 'litter', 'animal', 'cats', 'pet', 'kitten', 'cat']\n",
      "The top 10 words for topic#14\n",
      "['purchase', 'cheap', 'expensive', 'item', 'price', 'ring', 'store', 'sell', 'new', 'buy']\n",
      "The top 10 words for topic#15\n",
      "['tonight', 'dish', 'cooking', 'thanksgiving', 'table', 'meal', 'restaurant', 'night', 'cook', 'dinner']\n",
      "The top 10 words for topic#16\n",
      "['years', 'kids', 'divorce', 'married', 'sil', 'marriage', 'mil', 'marry', 'law', 'wife']\n",
      "The top 10 words for topic#17\n",
      "['dr', 'situation', 'point', 'throwaway', 'com', 'bit', 'https', 'reddit', 'edit', 'x200b']\n",
      "The top 10 words for topic#18\n",
      "['uncle', 'live', 'divorced', 'visit', 'bio', 'sibling', 'stepmom', 'step', 'divorce', 'dad']\n",
      "The top 10 words for topic#19\n",
      "['win', 'fun', 'music', 'player', 'playing', 'team', 'games', 'video', 'game', 'play']\n",
      "The top 10 words for topic#20\n",
      "['niece', 'adult', 'age', 'boy', 'nephew', 'run', 'young', 'old', 'kids', 'kid']\n",
      "The top 10 words for topic#21\n",
      "['graduation', 'degree', 'state', 'summer', 'university', 'study', 'semester', 'graduate', 'student', 'college']\n",
      "The top 10 words for topic#22\n",
      "['start', 'offer', 'hire', 'good', 'position', 'new', 'apply', 'interview', 'quit', 'job']\n",
      "The top 10 words for topic#23\n",
      "['ceremony', 'reception', 'married', 'bridesmaid', 'bride', 'fiance', 'wed', 'fiancé', 'marry', 'wedding']\n",
      "The top 10 words for topic#24\n",
      "['abusive', 'abuse', 'mil', 'live', 'sibling', 'speak', 'visit', 'law', 'grandmother', 'mother']\n",
      "The top 10 words for topic#25\n",
      "['okay', 'bring', 'years', 'cheat', 'love', 'uncomfortable', 'meet', 'doesn', 'upset', 'boyfriend']\n",
      "The top 10 words for topic#26\n",
      "['laws', 'marriage', 'married', 'fil', 'bil', 'marry', 'sil', 'law', 'mil', 'husband']\n",
      "The top 10 words for topic#27\n",
      "['halloween', 'parties', 'night', 'bachelorette', 'attend', 'bachelor', 'drunk', 'host', 'throw', 'party']\n",
      "The top 10 words for topic#28\n",
      "['wouldn', 'couldn', 'later', 'come', 'upset', 'need', 'lie', 'wasn', 'mad', 'tell']\n",
      "The top 10 words for topic#29\n",
      "['age', 'stepdaughter', 'step', 'pick', 'let', 'young', 'custody', 'niece', 'old', 'daughter']\n",
      "The top 10 words for topic#30\n",
      "['couch', 'guest', 'hotel', 'bed', 'tv', 'space', 'share', 'bedroom', 'living', 'room']\n",
      "The top 10 words for topic#31\n",
      "['grandson', 'step', 'weekend', 'pick', 'doesn', 'custody', 'nephew', 'old', 'boy', 'son']\n",
      "The top 10 words for topic#32\n",
      "['month', 'ago', 'new', 'current', 'cheat', 'custody', 'divorce', 'breakup', 'break', 'ex']\n",
      "The top 10 words for topic#33\n",
      "['uncomfortable', 'aita', 'mad', 'bring', 'best', 'cheat', 'love', 'asshole', 'upset', 'girlfriend']\n",
      "The top 10 words for topic#34\n",
      "['hate', 'asshole', 'line', 'racist', 'rude', 'black', 'white', 'lot', 'person', 'people']\n",
      "The top 10 words for topic#35\n",
      "['today', 'away', 'late', 'care', 'ride', 'hour', 'pick', 'bring', 'come', 'home']\n",
      "The top 10 words for topic#36\n",
      "['felt', 'love', 'distance', 'month', 'feeling', 'cheat', 'end', 'long', 'break', 'relationship']\n",
      "The top 10 words for topic#37\n",
      "['hospital', 'born', 'hold', 'abortion', 'month', 'birth', 'pregnancy', 'shower', 'pregnant', 'baby']\n",
      "The top 10 words for topic#38\n",
      "['friends', 'anymore', 'speak', 'listen', 'ignore', 'talking', 'hear', 'stop', 'conversation', 'talk']\n",
      "The top 10 words for topic#39\n",
      "['return', 'expensive', 'thank', 'receive', 'open', 'exchange', 'present', 'gifts', 'card', 'gift']\n",
      "The top 10 words for topic#40\n",
      "['owe', 'debt', 'saving', 'borrow', 'need', 'bank', 'account', 'spend', 'save', 'money']\n",
      "The top 10 words for topic#41\n",
      "['young', 'grow', 'grandparent', '18', 'allow', 'visit', 'live', 'sibling', 'parents', 'parent']\n",
      "The top 10 words for topic#42\n",
      "['housemate', 'bedroom', 'living', 'street', 'mortgage', 'yard', 'property', 'sell', 'live', 'house']\n",
      "The top 10 words for topic#43\n",
      "['cheat', 'doesn', 'bro', 'fight', 'upset', 'meet', 'mad', 'aita', 'gfs', 'gf']\n",
      "The top 10 words for topic#44\n",
      "['try', 'advice', 'struggle', 'refuse', 'thank', 'problem', 'situation', 'offer', 'need', 'help']\n",
      "The top 10 words for topic#45\n",
      "['come', 'bad', 'kind', 'felt', 'good', 'wasn', 'little', 'bit', 'pretty', 'look']\n",
      "The top 10 words for topic#46\n",
      "['episode', 'film', 'porn', 'theater', 'netflix', 'movies', 'video', 'tv', 'movie', 'watch']\n",
      "The top 10 words for topic#47\n",
      "['turn', 'new', 'cell', 'check', 'screen', 'iphone', 'answer', 'text', 'number', 'phone']\n",
      "The top 10 words for topic#48\n",
      "['explain', 'later', 'reply', 'come', 'today', 'okay', 'answer', 'yes', 'question', 'ask']\n",
      "The top 10 words for topic#49\n",
      "['window', 'aisle', 'seats', 'train', 'row', 'table', 'flight', 'bus', 'sit', 'seat']\n",
      "The top 10 words for topic#50\n",
      "['person', 'include', 'add', 'rest', 'friends', 'join', 'member', 'project', 'chat', 'group']\n",
      "The top 10 words for topic#51\n",
      "['refuse', 'holiday', 'university', 'shout', 'bit', 'apologise', 'quite', 'uni', 'speak', 'mum']\n",
      "The top 10 words for topic#52\n",
      "['cigarettes', 'outside', 'smoker', 'quit', 'drug', 'cigarette', 'smoking', 'smell', 'weed', 'smoke']\n",
      "The top 10 words for topic#53\n",
      "['upset', 'wish', 'celebration', 'surprise', 'birthdays', 'present', 'happy', 'celebrate', 'cake', 'birthday']\n",
      "The top 10 words for topic#54\n",
      "['semester', 'exam', 'study', 'project', 'professor', 'test', 'grade', 'student', 'teacher', 'class']\n",
      "The top 10 words for topic#55\n",
      "['homework', 'bully', 'bus', 'middle', 'senior', 'graduate', 'teacher', 'grade', 'high', 'school']\n",
      "The top 10 words for topic#56\n",
      "['isnt', 'wont', 'thats', 'wasnt', 'ive', 'doesnt', 'shes', 'didnt', 'dont', 'im']\n",
      "The top 10 words for topic#57\n",
      "['friends', 'night', 'cute', 'interested', 'flirt', 'dance', 'crush', 'boy', 'girls', 'girl']\n",
      "The top 10 words for topic#58\n",
      "['bar', 'nice', 'cheat', 'fuck', 'gay', 'meet', 'guys', 'man', 'dude', 'guy']\n",
      "The top 10 words for topic#59\n",
      "['food', 'table', 'pizza', 'waitress', 'delivery', 'server', 'service', 'restaurant', 'order', 'tip']\n",
      "The top 10 words for topic#60\n",
      "['grandpa', 'close', 'grandparent', 'funeral', 'cousins', 'grandmother', 'grandma', 'uncle', 'aunt', 'cousin']\n",
      "The top 10 words for topic#61\n",
      "['late', 'usually', 'spending', 'multiple', 'week', 'lot', 'hour', 'long', 'spend', 'time']\n",
      "The top 10 words for topic#62\n",
      "['decision', 'sense', 'effort', 'clear', 'fun', 'sure', 'comment', 'uncomfortable', 'joke', 'make']\n",
      "The top 10 words for topic#63\n",
      "['landlord', 'share', 'semester', 'issue', 'apartment', 'bathroom', 'dorm', 'roommates', 'lease', 'roommate']\n",
      "The top 10 words for topic#64\n",
      "['20', 'past', 'age', 'young', '10', 'years', 'new', 'ago', 'old', 'year']\n",
      "The top 10 words for topic#65\n",
      "['years', 'ok', 'comfortable', 'bff', 'dave', 'upset', 'doesn', 'bfs', 'bc', 'bf']\n",
      "The top 10 words for topic#66\n",
      "['break', 'schedule', 'sick', 'couple', 'days', 'later', 'ago', 'hour', 'week', 'day']\n",
      "The top 10 words for topic#67\n",
      "['europe', 'beach', 'country', 'visit', 'flight', 'hotel', 'book', 'travel', 'vacation', 'trip']\n",
      "The top 10 words for topic#68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wine', 'water', 'bottle', 'beer', 'night', 'alcohol', 'bar', 'drinking', 'drunk', 'drink']\n",
      "The top 10 words for topic#69\n",
      "['garage', 'lot', 'block', 'neighbor', 'driveway', 'space', 'street', 'parking', 'spot', 'park']\n",
      "The top 10 words for topic#70\n",
      "['outside', 'close', 'loud', 'hear', 'bathroom', 'knock', 'neighbor', 'lock', 'open', 'door']\n",
      "The top 10 words for topic#71\n",
      "['long', 'black', 'color', 'shower', 'look', 'haircut', 'shave', 'dye', 'cut', 'hair']\n",
      "The top 10 words for topic#72\n",
      "['lease', 'neighbor', 'complex', 'living', 'bedroom', 'building', 'city', 'place', 'live', 'apartment']\n",
      "The top 10 words for topic#73\n",
      "['word', 'password', 'change', 'toilet', 'computer', 'card', 'laptop', 'bathroom', 'account', 'use']\n",
      "The top 10 words for topic#74\n",
      "['festival', 'book', 'movie', 'plane', 'sell', 'event', 'band', 'tickets', 'concert', 'ticket']\n",
      "The top 10 words for topic#75\n",
      "['dates', 'week', 'months', 'woman', 'tinder', 'month', 'dating', 'start', 'meet', 'date']\n",
      "The top 10 words for topic#76\n",
      "['medium', 'social', 'comment', 'delete', 'instagram', 'account', 'facebook', 'photo', 'picture', 'post']\n",
      "The top 10 words for topic#77\n",
      "['new', 'coworkers', 'employee', 'boss', 'email', 'coworker', 'team', 'office', 'bos', 'company']\n",
      "The top 10 words for topic#78\n",
      "['biological', 'man', 'pass', 'funeral', 'grandfather', 'life', 'contact', 'divorce', 'step', 'father']\n",
      "The top 10 words for topic#79\n",
      "['kiss', 'pregnant', 'initiate', 'sexually', 'life', 'condom', 'porn', 'woman', 'sexual', 'sex']\n",
      "The top 10 words for topic#80\n",
      "['santa', 'tree', 'celebrate', 'thanksgiving', 'year', 'present', 'holiday', 'eve', 'spend', 'christmas']\n",
      "The top 10 words for topic#81\n",
      "['abortion', 'pregnancy', 'young', 'raise', 'woman', 'birth', 'pregnant', 'support', 'children', 'child']\n",
      "The top 10 words for topic#82\n",
      "['kind', 'mad', 'shit', 'laundry', 'box', 'throw', 'bag', 'lot', 'clothes', 'stuff']\n",
      "The top 10 words for topic#83\n",
      "['ready', '30', 'hour', 'decide', 'morning', 'left', 'wait', 'early', 'minute', 'leave']\n",
      "The top 10 words for topic#84\n",
      "['list', 'friends', 'guest', 'close', 'invitation', 'shower', 'event', 'invited', 'come', 'invite']\n",
      "The top 10 words for topic#85\n",
      "['awake', 'early', 'fall', 'couch', 'morning', 'asleep', 'night', 'wake', 'bed', 'sleep']\n",
      "The top 10 words for topic#86\n",
      "['yell', 'man', 'lady', 'street', 'woman', 'bus', 'wait', 'minute', 'away', 'walk']\n",
      "The top 10 words for topic#87\n",
      "['grocery', 'come', 'staff', 'schedule', 'coworker', 'employee', 'customer', 'shift', 'store', 'manager']\n",
      "The top 10 words for topic#88\n",
      "['license', 'road', 'gas', 'minute', 'driving', 'pick', 'driver', 'ride', 'hour', 'drive']\n",
      "The top 10 words for topic#89\n",
      "['holiday', 'upset', 'mil', 'partners', 'discuss', 'quite', 'project', 'ring', 'share', 'partner']\n",
      "The top 10 words for topic#90\n",
      "['uncle', 'nana', 'cancer', 'attend', 'die', 'away', 'pass', 'grandad', 'funeral', 'nan']\n",
      "The top 10 words for topic#91\n",
      "['offer', 'town', 'city', 'let', 'week', 'hotel', 'visit', 'place', 'night', 'stay']\n",
      "The top 10 words for topic#92\n",
      "['busy', 'hangout', 'meet', 'night', 'texted', 'anymore', 'text', 'friendship', 'friends', 'hang']\n",
      "The top 10 words for topic#93\n",
      "['issue', 'depression', 'best', 'anxiety', 'bad', 'care', 'health', 'mental', 'love', 'life']\n",
      "The top 10 words for topic#94\n",
      "['change', 'plans', 'week', 'sunday', 'friday', 'saturday', 'come', 'cancel', 'weekend', 'plan']\n",
      "The top 10 words for topic#95\n",
      "['eventually', 'act', 'fight', 'explain', 'ignore', 'point', 'yell', 'stop', 'start', 'try']\n",
      "The top 10 words for topic#96\n",
      "['suit', 'outfit', 'bra', 'black', 'look', 'ring', 'shirt', 'clothes', 'dress', 'wear']\n",
      "The top 10 words for topic#97\n",
      "['mark', 'joe', 'bob', 'mike', 'll', 'mary', 'sarah', 'let', 'jane', 'john']\n",
      "The top 10 words for topic#98\n",
      "['homophobic', 'atheist', 'catholic', 'god', 'christian', 'believe', 'religion', 'religious', 'gay', 'church']\n",
      "The top 10 words for topic#99\n",
      "['mean', 'let', 'problem', 'right', 'need', 'isn', 'won', 'doesn', 'll', 'thing']\n"
     ]
    }
   ],
   "source": [
    "nmf_model3 = NMF(n_components = 100)\n",
    "nmf_model3.fit(dtm_mystop)\n",
    "for index, topic in enumerate(nmf_model3.components_):\n",
    "  print(f\"The top 10 words for topic#{index}\")\n",
    "  print([tfidf_mystop.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "  #print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results3 = nmf_model3.transform(dtm_mystop)\n",
    "data['MystopTopic_100'] = topic_results3.argmax(axis = 1)\n",
    "#data['MystopTopic_100'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 7 words for topic#0\n",
      "['car', 'ask', 'tell', 'job', 'time', 'day', 'work']\n",
      "The top 7 words for topic#1\n",
      "['family', 'parent', 'tell', 'brother', 'sister', 'dad', 'mom']\n",
      "The top 7 words for topic#2\n",
      "['bark', 'animal', 'pet', 'walk', 'puppy', 'dogs', 'dog']\n",
      "The top 7 words for topic#3\n",
      "['month', 'job', 'car', 'rent', 'buy', 'money', 'pay']\n",
      "The top 7 words for topic#4\n",
      "['date', 'guy', 'group', 'girl', 'talk', 'tell', 'friend']\n",
      "The top 7 words for topic#5\n",
      "['year', 'son', 'daughter', 'husband', 'kid', 'wife', 'family']\n",
      "The top 7 words for topic#6\n",
      "['night', 'bed', 'cat', 'house', 'roommate', 'sleep', 'room']\n"
     ]
    }
   ],
   "source": [
    "nmf_model7 = NMF(n_components = 7)\n",
    "nmf_model7.fit(dtm_mystop)\n",
    "for index, topic in enumerate(nmf_model7.components_):\n",
    "  print(f\"The top 7 words for topic#{index}\")\n",
    "  print([tfidf_mystop.get_feature_names()[i] for i in topic.argsort()[-7:]])\n",
    "  #print('\\n')\n",
    "topic_results7 = nmf_model7.transform(dtm_mystop)\n",
    "data['MystopTopic_7'] = topic_results7.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 7 words for topic#0\n",
      "['honestly', 'basically', 'kinda', 'probably', 'kind', 'sure', 'pretty']\n",
      "The top 7 words for topic#1\n",
      "['hate', 'fight', 'anyways', 'divorce', 'yell', 'stepdad', 'mom']\n",
      "The top 7 words for topic#2\n",
      "['pet', 'animal', 'owner', 'bark', 'puppy', 'dogs', 'dog']\n",
      "The top 7 words for topic#3\n",
      "['debt', 'owe', 'insurance', 'payment', 'loan', 'cost', 'pay']\n",
      "The top 7 words for topic#4\n",
      "['agree', 'cover', 'fair', 'cost', '50', 'split', 'half']\n",
      "The top 7 words for topic#5\n",
      "['happy', 'kids', 'years', 'married', 'marriage', 'divorce', 'marry']\n",
      "The top 7 words for topic#6\n",
      "['flush', 'floor', 'pee', 'stall', 'paper', 'toilet', 'bathroom']\n",
      "The top 7 words for topic#7\n",
      "['vehicle', 'cars', 'damage', 'gas', 'accident', 'insurance', 'car']\n",
      "The top 7 words for topic#8\n",
      "['schedule', 'able', 'busy', 'worker', 'working', 'hard', 'work']\n",
      "The top 7 words for topic#9\n",
      "['pan', 'meat', 'chicken', 'kitchen', 'cooking', 'meal', 'cook']\n",
      "The top 7 words for topic#10\n",
      "['refuse', 'bil', 'nephew', 'si', 'twin', 'sisters', 'sister']\n",
      "The top 7 words for topic#11\n",
      "['female', 'crush', 'aita', 'recently', 'friendship', 'mutual', 'friend']\n",
      "The top 7 words for topic#12\n",
      "['20', 'boy', 'adult', '16', '18', 'age', 'young']\n",
      "The top 7 words for topic#13\n",
      "['vet', 'litter', 'animal', 'pet', 'cats', 'kitten', 'cat']\n",
      "The top 7 words for topic#14\n",
      "['amazing', 'absolutely', 'heart', 'hate', 'great', 'happy', 'love']\n",
      "The top 7 words for topic#15\n",
      "['angry', 'yell', 'little', 'twin', 'bro', 'brothers', 'brother']\n",
      "The top 7 words for topic#16\n",
      "['laws', 'kids', 'agree', 'discuss', 'great', 'aita', 'wife']\n",
      "The top 7 words for topic#17\n",
      "['idea', 'situation', 'tl', 'dr', 'bit', 'throwaway', 'x200b']\n",
      "The top 7 words for topic#18\n",
      "['yell', 'grow', 'divorced', 'bio', 'divorce', 'stepmom', 'dad']\n",
      "The top 7 words for topic#19\n",
      "['character', 'online', 'board', 'player', 'games', 'video', 'game']\n",
      "The top 7 words for topic#20\n",
      "['scream', 'babysit', 'adult', 'boy', 'run', 'kids', 'kid']\n",
      "The top 7 words for topic#21\n",
      "['ceremony', 'attend', 'bridesmaid', 'reception', 'bride', 'wed', 'wedding']\n",
      "The top 7 words for topic#22\n",
      "['kind', 'recently', 'quite', 'stress', 'parking', 'mean', 'lot']\n",
      "The top 7 words for topic#23\n",
      "['pregnancy', 'sils', 'bro', 'dh', 'pregnant', 'bil', 'sil']\n",
      "The top 7 words for topic#24\n",
      "['refuse', 'happen', 'slide', 'wouldn', 'borrow', 'won', 'let']\n",
      "The top 7 words for topic#25\n",
      "['21f', 'tl', 'jealous', 'boyfriends', 'okay', 'years', 'boyfriend']\n",
      "The top 7 words for topic#26\n",
      "['toddler', 'children', 'fil', 'laws', 'kids', 'bil', 'husband']\n",
      "The top 7 words for topic#27\n",
      "['bachelorette', 'attend', 'drunk', 'bachelor', 'host', 'throw', 'party']\n",
      "The top 7 words for topic#28\n",
      "['yesterday', 'wouldn', 'aita', 'secret', 'truth', 'shouldn', 'tell']\n",
      "The top 7 words for topic#29\n",
      "['17', '13', 'boy', '16', 'yr', 'lady', 'old']\n",
      "The top 7 words for topic#30\n",
      "['dorm', 'rooms', 'guest', 'hotel', 'bedroom', 'living', 'room']\n",
      "The top 7 words for topic#31\n",
      "['stepson', 'toy', 'grandson', 'nephew', 'custody', 'boy', 'son']\n",
      "The top 7 words for topic#32\n",
      "['mutual', 'split', 'divorce', 'current', 'custody', 'breakup', 'ex']\n",
      "The top 7 words for topic#33\n",
      "['argument', 'recently', 'girlfriends', 'aita', 'propose', 'current', 'girlfriend']\n",
      "The top 7 words for topic#34\n",
      "['gonna', 'dude', 'bitch', 'piss', 'fucking', 'fuck', 'shit']\n",
      "The top 7 words for topic#35\n",
      "['evening', 'return', 'tire', 'uber', 'head', 'ride', 'home']\n",
      "The top 7 words for topic#36\n",
      "['hasn', 'pregnant', 'fast', 'forward', 'months', 'ago', 'month']\n",
      "The top 7 words for topic#37\n",
      "['born', 'hold', 'abortion', 'birth', 'pregnancy', 'pregnant', 'baby']\n",
      "The top 7 words for topic#38\n",
      "['kinda', 'haven', 'listen', 'ignore', 'anymore', 'talking', 'talk']\n",
      "The top 7 words for topic#39\n",
      "['sleepover', 'allow', 'daughters', 'granddaughter', 'stepdaughter', 'custody', 'daughter']\n",
      "The top 7 words for topic#40\n",
      "['saving', 'loan', 'lend', 'owe', 'borrow', 'save', 'money']\n",
      "The top 7 words for topic#41\n",
      "['grow', '18', 'aren', 'grandparent', 'allow', 'parents', 'parent']\n",
      "The top 7 words for topic#42\n",
      "['inside', 'kick', 'property', 'housemate', 'bedroom', 'mortgage', 'house']\n",
      "The top 7 words for topic#43\n",
      "['parents', 'area', 'state', 'currently', 'country', 'living', 'live']\n",
      "The top 7 words for topic#44\n",
      "['current', 'hire', 'position', 'interview', 'apply', 'quit', 'job']\n",
      "The top 7 words for topic#45\n",
      "['fight', 'current', 'bff', 'bro', 'aita', 'gfs', 'gf']\n",
      "The top 7 words for topic#46\n",
      "['season', 'youtube', 'episode', 'netflix', 'porn', 'video', 'watch']\n",
      "The top 7 words for topic#47\n",
      "['cheater', 'believe', 'forgive', 'affair', 'cheating', 'trust', 'cheat']\n",
      "The top 7 words for topic#48\n",
      "['kinda', 'pack', 'bunch', 'bag', 'box', 'kind', 'stuff']\n",
      "The top 7 words for topic#49\n",
      "['molly', 'mike', 'sara', 'mary', 'alex', 'amy', 'sam']\n",
      "The top 7 words for topic#50\n",
      "['include', 'rest', 'add', 'join', 'member', 'chat', 'group']\n",
      "The top 7 words for topic#51\n",
      "['uk', 'whilst', 'shout', 'quite', 'apologise', 'uni', 'mum']\n",
      "The top 7 words for topic#52\n",
      "['smoker', 'quit', 'drug', 'cigarette', 'smoking', 'weed', 'smoke']\n",
      "The top 7 words for topic#53\n",
      "['celebration', 'surprise', 'birthdays', 'happy', 'present', 'celebrate', 'birthday']\n",
      "The top 7 words for topic#54\n",
      "['student', 'assignment', 'classmate', 'classes', 'semester', 'professor', 'class']\n",
      "The top 7 words for topic#55\n",
      "['bully', 'senior', 'middle', 'graduate', 'grade', 'high', 'school']\n",
      "The top 7 words for topic#56\n",
      "['gonna', 'ill', 'id', 'thats', 'shes', 'ive', 'im']\n",
      "The top 7 words for topic#57\n",
      "['cute', 'flirt', 'interested', 'crush', 'boy', 'girls', 'girl']\n",
      "The top 7 words for topic#58\n",
      "['bar', 'hook', 'kind', 'nice', 'guys', 'dude', 'guy']\n",
      "The top 7 words for topic#59\n",
      "['update', 'info', 'mention', 'add', 'thanks', 'thank', 'edit']\n",
      "The top 7 words for topic#60\n",
      "['uncles', 'aunts', 'grandparent', 'great', 'thanksgiving', 'cousins', 'aunt']\n",
      "The top 7 words for topic#61\n",
      "['charge', 'check', 'cell', 'screen', 'iphone', 'number', 'phone']\n",
      "The top 7 words for topic#62\n",
      "['run', 'mile', 'trash', 'far', 'pass', 'throw', 'away']\n",
      "The top 7 words for topic#63\n",
      "['ra', 'living', 'semester', 'lease', 'dorm', 'roommates', 'roommate']\n",
      "The top 7 words for topic#64\n",
      "['forward', '12', '15', 'years', '10', 'ago', 'year']\n",
      "The top 7 words for topic#65\n",
      "['years', 'ok', 'bff', 'dave', 'bfs', 'bc', 'bf']\n",
      "The top 7 words for topic#66\n",
      "['cost', 'flight', 'europe', 'guilt', 'hotel', 'travel', 'trip']\n",
      "The top 7 words for topic#67\n",
      "['wine', 'beer', 'bar', 'alcohol', 'drinking', 'drunk', 'drink']\n",
      "The top 7 words for topic#68\n",
      "['happened', 'forward', 'saw', 'fast', 'apologize', 'happen', 'later']\n",
      "The top 7 words for topic#69\n",
      "['block', 'garage', 'driveway', 'street', 'parking', 'spot', 'park']\n",
      "The top 7 words for topic#70\n",
      "['mean', 'bunch', 'aren', 'usually', 'hate', 'rude', 'people']\n",
      "The top 7 words for topic#71\n",
      "['salon', 'color', 'haircut', 'shave', 'dye', 'cut', 'hair']\n",
      "The top 7 words for topic#72\n",
      "['state', 'contract', 'agree', 'deposit', 'landlord', 'lease', 'sign']\n",
      "The top 7 words for topic#73\n",
      "['machine', 'drug', 'internet', 'word', 'computer', 'laptop', 'use']\n",
      "The top 7 words for topic#74\n",
      "['festival', 'plane', 'event', 'band', 'tickets', 'concert', 'ticket']\n",
      "The top 7 words for topic#75\n",
      "['helping', 'advice', 'homework', 'refuse', 'struggle', 'situation', 'help']\n",
      "The top 7 words for topic#76\n",
      "['adopt', 'pregnancy', 'raise', 'birth', 'pregnant', 'children', 'child']\n",
      "The top 7 words for topic#77\n",
      "['scream', 'raise', 'angry', 'stepfather', 'abusive', 'abuse', 'mother']\n",
      "The top 7 words for topic#78\n",
      "['die', 'stepmother', 'pass', 'grandfather', 'divorce', 'biological', 'father']\n",
      "The top 7 words for topic#79\n",
      "['oral', 'initiate', 'sexually', 'porn', 'condom', 'sexual', 'sex']\n",
      "The top 7 words for topic#80\n",
      "['backstory', 'background', 'kind', 'maybe', 'quite', 'bit', 'little']\n",
      "The top 7 words for topic#81\n",
      "['tree', 'thanksgiving', 'celebrate', 'holiday', 'present', 'eve', 'christmas']\n",
      "The top 7 words for topic#82\n",
      "['certain', 'list', 'example', 'sort', 'kind', 'happen', 'thing']\n",
      "The top 7 words for topic#83\n",
      "['return', 'receive', 'expensive', 'present', 'exchange', 'gifts', 'gift']\n",
      "The top 7 words for topic#84\n",
      "['morning', 'soon', 'note', 'leaving', 'early', 'left', 'leave']\n",
      "The top 7 words for topic#85\n",
      "['road', 'lane', 'motorcycle', 'lock', 'rid', 'ride', 'bike']\n",
      "The top 7 words for topic#86\n",
      "['finally', 'understand', 'ok', 'fine', 'couldn', 'coming', 'come']\n",
      "The top 7 words for topic#87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['delivery', 'waiter', 'restaurant', 'waitress', 'server', 'service', 'tip']\n",
      "The top 7 words for topic#88\n",
      "['emotionally', 'great', 'toxic', 'open', 'abusive', 'distance', 'relationship']\n",
      "The top 7 words for topic#89\n",
      "['set', 'prom', 'months', 'dates', 'tinder', 'dating', 'date']\n",
      "The top 7 words for topic#90\n",
      "['saw', 'gathering', 'grow', 'drama', 'relative', 'cousins', 'cousin']\n",
      "The top 7 words for topic#91\n",
      "['weeks', 'drug', 'hasn', 'months', 'haven', 'years', 'past']\n",
      "The top 7 words for topic#92\n",
      "['kick', 'fear', 'pass', 'nana', 'grandad', 'funeral', 'nan']\n",
      "The top 7 words for topic#93\n",
      "['completely', 'tie', 'block', 'number', 'reach', 'cut', 'contact']\n",
      "The top 7 words for topic#94\n",
      "['aita', 'whilst', 'holiday', 'discuss', 'quite', 'partners', 'partner']\n",
      "The top 7 words for topic#95\n",
      "['friday', 'twice', 'schedule', 'notice', 'weeks', 'ago', 'week']\n",
      "The top 7 words for topic#96\n",
      "['maybe', 'title', 'wonder', 'recently', 'reddit', 'situation', 'asshole']\n",
      "The top 7 words for topic#97\n",
      "['cool', 'outside', 'friendship', 'busy', 'hangout', 'anymore', 'hang']\n",
      "The top 7 words for topic#98\n",
      "['hand', 'notice', 'forward', 'saw', 'eye', 'face', 'look']\n",
      "The top 7 words for topic#99\n",
      "['fine', 'reply', 'asking', 'ok', 'okay', 'yes', 'ask']\n",
      "The top 7 words for topic#100\n",
      "['tonight', 'bar', 'morning', 'saturday', 'drunk', 'friday', 'night']\n",
      "The top 7 words for topic#101\n",
      "['act', 'convince', 'possible', 'ignore', 'hard', 'explain', 'try']\n",
      "The top 7 words for topic#102\n",
      "['believe', 'sure', 'left', 'situation', 'maybe', 'wrong', 'right']\n",
      "The top 7 words for topic#103\n",
      "['area', 'hometown', 'travel', 'different', 'small', 'town', 'city']\n",
      "The top 7 words for topic#104\n",
      "['catholic', 'god', 'christian', 'believe', 'religion', 'religious', 'church']\n",
      "The top 7 words for topic#105\n",
      "['crying', 'fight', 'act', 'soon', 'eventually', 'yell', 'start']\n",
      "The top 7 words for topic#106\n",
      "['left', 'traffic', 'speed', 'road', 'lane', 'light', 'turn']\n",
      "The top 7 words for topic#107\n",
      "['attend', 'list', 'guest', 'invitation', 'event', 'invited', 'invite']\n",
      "The top 7 words for topic#108\n",
      "['proposal', 'jewelry', 'band', 'diamond', 'propose', 'engagement', 'ring']\n",
      "The top 7 words for topic#109\n",
      "['fb', 'reddit', 'delete', 'instagram', 'comment', 'facebook', 'post']\n",
      "The top 7 words for topic#110\n",
      "['messages', 'chat', 'block', 'facebook', 'respond', 'reply', 'message']\n",
      "The top 7 words for topic#111\n",
      "['fun', 'decision', 'effort', 'comment', 'clear', 'sure', 'make']\n",
      "The top 7 words for topic#112\n",
      "['okay', 'sure', 'fine', 'worry', 'probably', 'won', 'll']\n",
      "The top 7 words for topic#113\n",
      "['couldn', 'choose', 'instead', 'agree', 'finally', 'decision', 'decide']\n",
      "The top 7 words for topic#114\n",
      "['eve', 'replace', 'happy', 'recently', 'york', 'brand', 'new']\n",
      "The top 7 words for topic#115\n",
      "['humor', 'joking', 'fun', 'jokes', 'laugh', 'funny', 'joke']\n",
      "The top 7 words for topic#116\n",
      "['lunch', 'anymore', 'winter', 'spring', 'heart', 'breakup', 'break']\n",
      "The top 7 words for topic#117\n",
      "['country', 'met', 'introduce', 'online', 'tinder', 'meeting', 'meet']\n",
      "The top 7 words for topic#118\n",
      "['evening', 'meal', 'tonight', 'nice', 'thanksgiving', 'restaurant', 'dinner']\n",
      "The top 7 words for topic#119\n",
      "['saw', 'aisle', 'yell', 'sidewalk', 'walking', 'street', 'walk']\n",
      "The top 7 words for topic#120\n",
      "['struggle', 'therapy', 'therapist', 'depression', 'anxiety', 'health', 'mental']\n",
      "The top 7 words for topic#121\n",
      "['dementia', 'grandparents', 'great', 'die', 'grandparent', 'grandpa', 'grandma']\n",
      "The top 7 words for topic#122\n",
      "['pair', 'afford', 'purchase', 'cheap', 'present', 'expensive', 'buy']\n",
      "The top 7 words for topic#123\n",
      "['able', 'planning', 'tomorrow', 'wibta', 'plans', 'cancel', 'plan']\n",
      "The top 7 words for topic#124\n",
      "['seats', 'ignore', 'desk', 'couch', 'stand', 'chair', 'sit']\n",
      "The top 7 words for topic#125\n",
      "['xbox', 'switch', 'guitar', 'fun', 'games', 'playing', 'play']\n",
      "The top 7 words for topic#126\n",
      "['suppose', 'earlier', 'aita', 'yesterday', 'tomorrow', 'lunch', 'today']\n",
      "The top 7 words for topic#127\n",
      "['steve', 'bob', 'mark', 'hannah', 'mary', 'mike', 'john']\n",
      "The top 7 words for topic#128\n",
      "['horror', 'theatre', 'cinema', 'film', 'movies', 'theater', 'movie']\n",
      "The top 7 words for topic#129\n",
      "['diet', 'overweight', 'body', 'gain', 'fat', 'lose', 'weight']\n",
      "The top 7 words for topic#130\n",
      "['subject', 'potluck', 'topic', 'host', 'fact', 'mention', 'bring']\n",
      "The top 7 words for topic#131\n",
      "['felt', 'situation', 'hug', 'comfortable', 'kiss', 'weird', 'uncomfortable']\n",
      "The top 7 words for topic#132\n",
      "['learn', 'figure', 'needs', 'needed', 'explain', 'fine', 'need']\n",
      "The top 7 words for topic#133\n",
      "['horrible', 'mood', 'sound', 'kinda', 'sorry', 'felt', 'bad']\n",
      "The top 7 words for topic#134\n",
      "['feed', 'plate', 'fridge', 'hungry', 'restaurant', 'fast', 'food']\n",
      "The top 7 words for topic#135\n",
      "['lgbt', 'lesbian', 'bi', 'sexuality', 'straight', 'homophobic', 'gay']\n",
      "The top 7 words for topic#136\n",
      "['landlord', 'living', 'floor', 'bedroom', 'complex', 'building', 'apartment']\n",
      "The top 7 words for topic#137\n",
      "['plane', 'seats', 'window', 'aisle', 'row', 'flight', 'seat']\n",
      "The top 7 words for topic#138\n",
      "['ignore', 'texts', 'reply', 'texting', 'respond', 'texted', 'text']\n",
      "The top 7 words for topic#139\n",
      "['maid', 'years', 'honor', 'bff', 'happy', 'friendship', 'best']\n",
      "The top 7 words for topic#140\n",
      "['native', 'country', 'learn', 'spanish', 'language', 'english', 'speak']\n",
      "The top 7 words for topic#141\n",
      "['public', 'uber', 'catch', 'wait', 'ride', 'driver', 'bus']\n",
      "The top 7 words for topic#142\n",
      "['terrible', 'toxic', 'horrible', 'nice', 'type', 'kind', 'person']\n",
      "The top 7 words for topic#143\n",
      "['log', 'netflix', 'access', 'throwaway', 'password', 'bank', 'account']\n",
      "The top 7 words for topic#144\n",
      "['trash', 'bag', 'uber', 'ride', 'airport', 'drop', 'pick']\n",
      "The top 7 words for topic#145\n",
      "['art', 'body', 'idea', 'design', 'tattoos', 'artist', 'tattoo']\n",
      "The top 7 words for topic#146\n",
      "['schedule', 'thursday', 'monday', 'sunday', 'friday', 'saturday', 'weekend']\n",
      "The top 7 words for topic#147\n",
      "['overnight', 'days', 'comfortable', 'guest', 'airbnb', 'hotel', 'stay']\n",
      "The top 7 words for topic#148\n",
      "['attractive', 'lady', 'male', 'female', 'women', 'men', 'woman']\n",
      "The top 7 words for topic#149\n",
      "['awake', 'snore', 'bedroom', 'sleeping', 'asleep', 'couch', 'sleep']\n",
      "The top 7 words for topic#150\n",
      "['sheet', 'bedroom', 'mattress', 'couch', 'asleep', 'lay', 'bed']\n",
      "The top 7 words for topic#151\n",
      "['area', 'parking', 'bag', 'personal', 'small', 'bedroom', 'space']\n",
      "The top 7 words for topic#152\n",
      "['okay', 'explain', 'aita', 'apologize', 'angry', 'understand', 'upset']\n",
      "The top 7 words for topic#153\n",
      "['charge', 'debt', 'debit', 'cards', 'cash', 'credit', 'card']\n",
      "The top 7 words for topic#154\n",
      "['animal', 'feed', 'wouldn', 'anymore', 'responsibility', 'pet', 'care']\n",
      "The top 7 words for topic#155\n",
      "['load', 'machine', 'wash', 'washer', 'dryer', 'laundry', 'clothes']\n",
      "The top 7 words for topic#156\n",
      "['football', 'sport', 'player', 'member', 'win', 'coach', 'team']\n",
      "The top 7 words for topic#157\n",
      "['awake', 'fall', 'early', 'alarm', 'asleep', 'morning', 'wake']\n",
      "The top 7 words for topic#158\n",
      "['free', 'times', 'waste', 'usually', 'busy', 'multiple', 'time']\n",
      "The top 7 words for topic#159\n",
      "['flight', 'hospital', 'state', 'travel', 'fly', 'country', 'visit']\n",
      "The top 7 words for topic#160\n",
      "['30', 'extra', '40', '24', '12', 'hours', 'hour']\n",
      "The top 7 words for topic#161\n",
      "['lurker', 'period', 'term', 'distance', 'short', 'story', 'long']\n",
      "The top 7 words for topic#162\n",
      "['happy', 'reason', 'better', 'nice', 'great', 'idea', 'good']\n",
      "The top 7 words for topic#163\n",
      "['isnt', 'wont', 'wasnt', 'doesnt', 'shes', 'didnt', 'dont']\n",
      "The top 7 words for topic#164\n",
      "['schedule', 'different', 'diaper', 'subject', 'password', 'mind', 'change']\n",
      "The top 7 words for topic#165\n",
      "['nice', 'cheap', 'public', 'suggest', 'crash', 'places', 'place']\n",
      "The top 7 words for topic#166\n",
      "['busy', 'single', 'schedule', 'valentine', 'rest', 'days', 'day']\n",
      "The top 7 words for topic#167\n",
      "['ignore', 'smoking', 'constantly', 'eventually', 'annoy', 'continue', 'stop']\n",
      "The top 7 words for topic#168\n",
      "['street', 'neighborhood', 'outside', 'property', 'fence', 'yard', 'neighbor']\n",
      "The top 7 words for topic#169\n",
      "['rest', 'immediate', 'extended', 'holiday', 'thanksgiving', 'member', 'family']\n",
      "The top 7 words for topic#170\n",
      "['reading', 'books', 'hotel', 'flight', 'holiday', 'read', 'book']\n",
      "The top 7 words for topic#171\n",
      "['free', 'afford', 'landlord', 'lease', 'utility', 'split', 'rent']\n",
      "The top 7 words for topic#172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aren', 'closer', 'consider', 'grow', 'friendship', 'super', 'close']\n",
      "The top 7 words for topic#173\n",
      "['entire', 'drug', 'hard', 'real', 'grow', 'happy', 'life']\n",
      "The top 7 words for topic#174\n",
      "['tables', 'waitress', 'bar', 'lunch', 'server', 'restaurant', 'table']\n",
      "The top 7 words for topic#175\n",
      "['diet', 'hungry', 'eating', 'pizza', 'meal', 'lunch', 'eat']\n",
      "The top 7 words for topic#176\n",
      "['wait', 'minutes', '15', '20', '30', '10', 'minute']\n",
      "The top 7 words for topic#177\n",
      "['semester', 'uni', 'final', 'university', 'student', 'exam', 'study']\n",
      "The top 7 words for topic#178\n",
      "['fiancés', 'propose', 'engagement', 'engaged', 'future', 'engage', 'fiancé']\n",
      "The top 7 words for topic#179\n",
      "['towel', 'morning', 'pee', 'wash', 'showers', 'bridal', 'shower']\n",
      "The top 7 words for topic#180\n",
      "['check', 'essay', 'paper', 'note', 'read', 'letter', 'write']\n",
      "The top 7 words for topic#181\n",
      "['quit', 'meeting', 'coworkers', 'worker', 'employee', 'boss', 'bos']\n",
      "The top 7 words for topic#182\n",
      "['situation', 'summer', 'happen', 'argument', 'fight', 'friendship', 'end']\n",
      "The top 7 words for topic#183\n",
      "['department', 'assistant', 'restaurant', 'staff', 'customer', 'employee', 'manager']\n",
      "The top 7 words for topic#184\n",
      "['shopping', 'cashier', 'item', 'shop', 'grocery', 'customer', 'store']\n",
      "The top 7 words for topic#185\n",
      "['instagram', 'face', 'delete', 'profile', 'pic', 'pictures', 'picture']\n",
      "The top 7 words for topic#186\n",
      "['principal', 'classroom', 'lesson', 'teach', 'student', 'grade', 'teacher']\n",
      "The top 7 words for topic#187\n",
      "['summer', 'state', 'graduation', 'student', 'semester', 'graduate', 'college']\n",
      "The top 7 words for topic#188\n",
      "['bridal', 'bride', 'shopping', 'prom', 'dresses', 'bridesmaid', 'dress']\n",
      "The top 7 words for topic#189\n",
      "['facebook', 'camera', 'instagram', 'photographer', 'delete', 'photos', 'photo']\n",
      "The top 7 words for topic#190\n",
      "['american', 'asian', 'race', 'word', 'racist', 'white', 'black']\n",
      "The top 7 words for topic#191\n",
      "['happen', 'days', 'months', 'times', 'weeks', 'ago', 'couple']\n",
      "The top 7 words for topic#192\n",
      "['contract', 'department', 'hire', 'employee', 'position', 'interview', 'company']\n",
      "The top 7 words for topic#193\n",
      "['mean', 'apologize', 'friendship', 'felt', 'feelings', 'feeling', 'hurt']\n",
      "The top 7 words for topic#194\n",
      "['uncles', 'died', 'die', 'cousins', 'grandpa', 'grandparent', 'uncle']\n",
      "The top 7 words for topic#195\n",
      "['ride', 'position', 'refuse', 'decline', 'free', 'accept', 'offer']\n",
      "The top 7 words for topic#196\n",
      "['engaged', 'jake', 'engagement', 'marry', 'future', 'engage', 'fiance']\n",
      "The top 7 words for topic#197\n",
      "['outside', 'slam', 'key', 'knock', 'lock', 'open', 'door']\n",
      "The top 7 words for topic#198\n",
      "['aita', 'cost', 'information', 'fair', 'personal', 'split', 'share']\n",
      "The top 7 words for topic#199\n",
      "['cancer', 'medical', 'appointment', 'pain', 'surgery', 'hospital', 'doctor']\n",
      "The top 7 words for topic#200\n",
      "['screenshot', 'package', 'nude', 'mail', 'video', 'pic', 'send']\n",
      "The top 7 words for topic#201\n",
      "['jacket', 'suit', 'clothes', 'shoe', 'bra', 'shirt', 'wear']\n",
      "The top 7 words for topic#202\n",
      "['cruise', 'enjoy', 'travel', 'flight', 'beach', 'summer', 'vacation']\n",
      "The top 7 words for topic#203\n",
      "['dirty', 'floor', 'trash', 'kitchen', 'cleaning', 'mess', 'clean']\n",
      "The top 7 words for topic#204\n",
      "['cover', 'stomach', 'fever', 'cough', 'flu', 'cold', 'sick']\n",
      "The top 7 words for topic#205\n",
      "['remain', 'male', 'act', 'female', 'mutual', 'friendship', 'friends']\n",
      "The top 7 words for topic#206\n",
      "['basically', 'actually', 'argue', 'fact', 'view', 'argument', 'point']\n",
      "The top 7 words for topic#207\n",
      "['miss', 'kids', 'spouse', 'grow', 'holiday', 'siblings', 'sibling']\n",
      "The top 7 words for topic#208\n",
      "['trainer', 'bench', 'set', 'machine', 'membership', 'workout', 'gym']\n",
      "The top 7 words for topic#209\n",
      "['death', 'attend', 'pass', 'die', 'grandfather', 'funeral', 'grandmother']\n",
      "The top 7 words for topic#210\n",
      "['concert', 'loud', 'sing', 'band', 'listen', 'song', 'music']\n",
      "The top 7 words for topic#211\n",
      "['hubby', 'amy', 'dh', 'laws', 'bil', 'fil', 'mil']\n",
      "The top 7 words for topic#212\n",
      "['bil', 'present', 'kids', 'nephews', 'babysit', 'nephew', 'niece']\n",
      "The top 7 words for topic#213\n",
      "['super', 'angry', 'fight', 'apologize', 'yell', 'aita', 'mad']\n",
      "The top 7 words for topic#214\n",
      "['tom', 'amy', 'bob', 'jack', 'mary', 'joe', 'jane']\n",
      "The top 7 words for topic#215\n",
      "['trust', 'liar', 'reason', 'lying', 'truth', 'believe', 'lie']\n",
      "The top 7 words for topic#216\n",
      "['dna', 'pass', 'pregnancy', 'drug', 'pregnant', 'grade', 'test']\n",
      "The top 7 words for topic#217\n",
      "['anymore', 'matter', 'mean', 'won', 'understand', 'isn', 'doesn']\n",
      "The top 7 words for topic#218\n",
      "['subway', 'puppy', 'gas', 'training', 'bag', 'station', 'train']\n",
      "The top 7 words for topic#219\n",
      "['extra', 'shifts', 'supervisor', 'coworker', 'schedule', 'cover', 'shift']\n",
      "The top 7 words for topic#220\n",
      "['scream', 'sound', 'yell', 'quiet', 'noise', 'loud', 'hear']\n",
      "The top 7 words for topic#221\n",
      "['rude', 'wrong', 'simple', 'explain', 'questions', 'question', 'answer']\n",
      "The top 7 words for topic#222\n",
      "['http', 'comments', 'www', 'reddit', 'imgur', 'https', 'com']\n",
      "The top 7 words for topic#223\n",
      "['film', 'professor', 'present', 'presentation', 'finish', 'grade', 'project']\n",
      "The top 7 words for topic#224\n",
      "['worker', 'coffee', 'desk', 'coworkers', 'lunch', 'coworker', 'office']\n",
      "The top 7 words for topic#225\n",
      "['issues', 'fight', 'fix', 'isn', 'cause', 'issue', 'problem']\n",
      "The top 7 words for topic#226\n",
      "['restaurant', 'meal', 'diet', 'animal', 'vegetarian', 'meat', 'vegan']\n",
      "The top 7 words for topic#227\n",
      "['abortion', 'situation', 'financial', 'emotional', 'decision', 'financially', 'support']\n",
      "The top 7 words for topic#228\n",
      "['hand', 'kitchen', 'dishwasher', 'sink', 'dishes', 'wash', 'dish']\n",
      "The top 7 words for topic#229\n",
      "['perfume', 'deodorant', 'notice', 'hygiene', 'stink', 'strong', 'smell']\n",
      "The top 7 words for topic#230\n",
      "['deliver', 'driver', 'customer', 'restaurant', 'delivery', 'pizza', 'order']\n",
      "The top 7 words for topic#231\n",
      "['realize', 'happy', 'sure', 'wouldn', 'couldn', 'felt', 'wasn']\n",
      "The top 7 words for topic#232\n",
      "['ride', 'road', 'license', 'gas', 'driver', 'driving', 'drive']\n",
      "The top 7 words for topic#233\n",
      "['cut', 'ahead', 'cashier', 'stand', 'lady', 'wait', 'line']\n",
      "The top 7 words for topic#234\n",
      "['xbox', 'ps4', 'bedroom', 'volume', 'couch', 'living', 'tv']\n",
      "The top 7 words for topic#235\n",
      "['mean', 'respond', 'topic', 'mention', 'kind', 'rude', 'conversation']\n",
      "The top 7 words for topic#236\n",
      "['shop', 'employee', 'small', 'owner', 'mind', 'run', 'business']\n",
      "The top 7 words for topic#237\n",
      "['stand', 'dude', 'grown', 'saw', 'homeless', 'men', 'man']\n",
      "The top 7 words for topic#238\n",
      "['biological', 'stepmom', 'foot', 'stepdad', 'bio', 'cause', 'step']\n",
      "The top 7 words for topic#239\n",
      "['value', 'art', 'free', 'sale', 'item', 'price', 'sell']\n",
      "The top 7 words for topic#240\n",
      "['argument', 'isn', 'small', 'fight', 'huge', 'deal', 'big']\n",
      "The top 7 words for topic#241\n",
      "['state', 'legal', 'police', 'lawyer', 'fil', 'laws', 'law']\n",
      "The top 7 words for topic#242\n",
      "['anxiety', 'event', 'number', 'media', 'block', 'medium', 'social']\n",
      "The top 7 words for topic#243\n",
      "['cold', 'glass', 'cup', 'hot', 'bag', 'bottle', 'water']\n",
      "The top 7 words for topic#244\n",
      "['ready', '30', 'arrive', 'run', 'event', 'early', 'late']\n",
      "The top 7 words for topic#245\n",
      "['interview', 'respond', 'meeting', 'reply', 'address', 'receive', 'email']\n",
      "The top 7 words for topic#246\n",
      "['jack', 'mike', 'anna', 'james', 'mark', 'jake', 'sarah']\n",
      "The top 7 words for topic#247\n",
      "['slice', 'piece', 'bake', 'chocolate', 'cream', 'ice', 'cake']\n",
      "The top 7 words for topic#248\n",
      "['nye', 'instead', 'thanksgiving', 'enjoy', 'holiday', 'spending', 'spend']\n",
      "The top 7 words for topic#249\n",
      "['prom', 'fun', 'dancing', 'event', 'bar', 'club', 'dance']\n"
     ]
    }
   ],
   "source": [
    "nmf_model250 = NMF(n_components = 250)\n",
    "nmf_model250.fit(dtm_mystop)\n",
    "for index, topic in enumerate(nmf_model250.components_):\n",
    "  print(f\"The top 7 words for topic#{index}\")\n",
    "  print([tfidf_mystop.get_feature_names()[i] for i in topic.argsort()[-7:]])\n",
    "  #print('\\n')\n",
    "topic_results250 = nmf_model250.transform(dtm_mystop)\n",
    "data['MystopTopic_250'] = topic_results250.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aita_labels = data[['id','MystopTopic_10','MystopTopic_100','MystopTopic_250']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MystopTopic_10</th>\n",
       "      <th>MystopTopic_100</th>\n",
       "      <th>MystopTopic_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1yuc78</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yueqb</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  MystopTopic_10  MystopTopic_100  MystopTopic_250\n",
       "0  1ytxov               0               76                0\n",
       "1  1yu29c               9               91               14\n",
       "2  1yu8hi               0                0                0\n",
       "3  1yuc78               0               76              222\n",
       "4  1yueqb               1               90               92"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aita_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aita_labels.to_csv('aita_labels10100250.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
